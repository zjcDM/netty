17年校招进入华为一直工作至今，期间第一个项目是做数据库迁移服务，其中比较有挑战的工作是独立负责mongodb引擎的迁移。从方案调研以及落地上线全部由我自己完成，期间从使用开源工具到借助tungsten框架实现自研开发，最终实现了在ycsb模型下全量迁移70%场景性能超越友商，增量性能持平。在此基础上，构建自己的差异化竞争力，支持迁移账号权限，验证器，固定集合以及分片集群的迁移。

全量性能保证：
1、对集合进行分片，提高迁移的并行度。这边分片的方案先按类型分片，如果类型是objectid和数值类型，则继续分片。如果是数值类型，那么可以获取最大和最小的值，按一定大小的间隔进行分片。如果是objecid，因为objectid是由4部分组成的，最前面的是时间戳，所以可以获取到最大和最小的objectid，然后按照时间间隔进行分片。
2、全量期间的迁移，数据不落盘，全部走内存。
3、索引的创建时机，因为mongo的索引可以前台创建和后台创建，前台创建速度快，但是有限制，每一个db只有500m内存供创建索引，而且是阻塞式创建，所以一个在迁移的db中有多个collection，就会互相影响。而后台创建索引，是cpu时间空闲的时候才会创建，而在迁移期间，cpu是不空闲的，所以后台创建索引耗费的时间非常长。因此我们的方案折中，在迁移数据之前迁移索引，耗费的时间刚好在这两种方式之间。
4、批量插入，并且是否有序的参数设置为false
增量性能保证：
1、冲突高的、流量低的单线程回放。流量高的冲突低的并行回放。因为冲突高的流量低的做一系列冲突检测是多余的，单线程批量回放即可。而流量高的冲突低的，通过冲突检测进行并行回放，可以明显增加回放速度。

针对分片集群：
1、全量分片规则修改，全部按chunk进行分片。查询请求不包含shard key，则必须将查询分发到所有的shard，然后合并查询结果返回给客户端；查询请求包含shard key，则直接根据shard key计算出需要查询的chunk，向对应的shard发送查询请求
2、如果是hash分片，则提前预置chunks，减少chunk分裂。
3、分片的回放按照目标库chunk范围提前分组，避免在server写入时收到最小时延的shard的影响

第二个项目是开发华为搜索数据平台（就是去年随P40发布的petal search，花瓣搜索），这个项目是我带几个外包和一个新员工一起做的，在这个项目中，我的主要工作是数据从接入到下游的流程架构设计，异构数据统一方案设计，核心代码开发，与内容提供商需求交流接洽，以及整个项目的转测发布规划跟踪。最终成功接入20多个内容提供商的数据，性能上满足各个内容提供商的更新需求，及时支持搜索上线。


最近在做也是支撑华为搜索的在线检索引擎的优化，前期主要做特性开发，主要涉及elasticsearch分片的分配特性需求开发，近几个月主要是做性能优化，一个是scriptscorefunction打分优化，通过自定义docvalues数据结构，每个scriptscorefunction共享缓存，单次检索时延平均降低18ms。另一个优化工作是，对scoreFunction的得分进行缓存，业务场景中的不变的scorefunction和高频scorefunction的得分提前缓存，单次检索时延平均降低15ms。
